{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Analytics\\\\Personal\\\\Machine Learning\\\\Training\\\\R\\\\Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['times_pregnant' 'Plasma_glucose_concentration_2 hr' 'blood_pressure'\n",
      " ' Triceps_skin_fold_thickness ' ' Hr2_serum_insulin' 'BOI'\n",
      " ' Diabetes_pedigree_function' 'Age' 'Class']\n"
     ]
    }
   ],
   "source": [
    "# read the data in\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics :\n",
      "        times_pregnant  Plasma_glucose_concentration_2 hr  blood_pressure  \\\n",
      "count      768.000000                         768.000000      768.000000   \n",
      "mean         3.845052                         120.894531       69.105469   \n",
      "std          3.369578                          31.972618       19.355807   \n",
      "min          0.000000                           0.000000        0.000000   \n",
      "25%          1.000000                          99.000000       62.000000   \n",
      "50%          3.000000                         117.000000       72.000000   \n",
      "75%          6.000000                         140.250000       80.000000   \n",
      "max         17.000000                         199.000000      122.000000   \n",
      "\n",
      "        Triceps_skin_fold_thickness    Hr2_serum_insulin         BOI  \\\n",
      "count                     768.000000          768.000000  768.000000   \n",
      "mean                       20.536458           79.799479   31.992578   \n",
      "std                        15.952218          115.244002    7.884160   \n",
      "min                         0.000000            0.000000    0.000000   \n",
      "25%                         0.000000            0.000000   27.300000   \n",
      "50%                        23.000000           30.500000   32.000000   \n",
      "75%                        32.000000          127.250000   36.600000   \n",
      "max                        99.000000          846.000000   67.100000   \n",
      "\n",
      "        Diabetes_pedigree_function         Age       Class  \n",
      "count                   768.000000  768.000000  768.000000  \n",
      "mean                      0.471876   33.240885    0.348958  \n",
      "std                       0.331329   11.760232    0.476951  \n",
      "min                       0.078000   21.000000    0.000000  \n",
      "25%                       0.243750   24.000000    0.000000  \n",
      "50%                       0.372500   29.000000    0.000000  \n",
      "75%                       0.626250   41.000000    1.000000  \n",
      "max                       2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Summary Statistics :\\n\",df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>Plasma_glucose_concentration_2 hr</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>Triceps_skin_fold_thickness</th>\n",
       "      <th>Hr2_serum_insulin</th>\n",
       "      <th>BOI</th>\n",
       "      <th>Diabetes_pedigree_function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>times_pregnant</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plasma_glucose_concentration_2 hr</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_pressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triceps_skin_fold_thickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hr2_serum_insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOI</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes_pedigree_function</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   times_pregnant  \\\n",
       "times_pregnant                           1.000000   \n",
       "Plasma_glucose_concentration_2 hr        0.129459   \n",
       "blood_pressure                           0.141282   \n",
       " Triceps_skin_fold_thickness            -0.081672   \n",
       " Hr2_serum_insulin                      -0.073535   \n",
       "BOI                                      0.017683   \n",
       " Diabetes_pedigree_function             -0.033523   \n",
       "Age                                      0.544341   \n",
       "Class                                    0.221898   \n",
       "\n",
       "                                   Plasma_glucose_concentration_2 hr  \\\n",
       "times_pregnant                                              0.129459   \n",
       "Plasma_glucose_concentration_2 hr                           1.000000   \n",
       "blood_pressure                                              0.152590   \n",
       " Triceps_skin_fold_thickness                                0.057328   \n",
       " Hr2_serum_insulin                                          0.331357   \n",
       "BOI                                                         0.221071   \n",
       " Diabetes_pedigree_function                                 0.137337   \n",
       "Age                                                         0.263514   \n",
       "Class                                                       0.466581   \n",
       "\n",
       "                                   blood_pressure  \\\n",
       "times_pregnant                           0.141282   \n",
       "Plasma_glucose_concentration_2 hr        0.152590   \n",
       "blood_pressure                           1.000000   \n",
       " Triceps_skin_fold_thickness             0.207371   \n",
       " Hr2_serum_insulin                       0.088933   \n",
       "BOI                                      0.281805   \n",
       " Diabetes_pedigree_function              0.041265   \n",
       "Age                                      0.239528   \n",
       "Class                                    0.065068   \n",
       "\n",
       "                                    Triceps_skin_fold_thickness   \\\n",
       "times_pregnant                                         -0.081672   \n",
       "Plasma_glucose_concentration_2 hr                       0.057328   \n",
       "blood_pressure                                          0.207371   \n",
       " Triceps_skin_fold_thickness                            1.000000   \n",
       " Hr2_serum_insulin                                      0.436783   \n",
       "BOI                                                     0.392573   \n",
       " Diabetes_pedigree_function                             0.183928   \n",
       "Age                                                    -0.113970   \n",
       "Class                                                   0.074752   \n",
       "\n",
       "                                    Hr2_serum_insulin       BOI  \\\n",
       "times_pregnant                              -0.073535  0.017683   \n",
       "Plasma_glucose_concentration_2 hr            0.331357  0.221071   \n",
       "blood_pressure                               0.088933  0.281805   \n",
       " Triceps_skin_fold_thickness                 0.436783  0.392573   \n",
       " Hr2_serum_insulin                           1.000000  0.197859   \n",
       "BOI                                          0.197859  1.000000   \n",
       " Diabetes_pedigree_function                  0.185071  0.140647   \n",
       "Age                                         -0.042163  0.036242   \n",
       "Class                                        0.130548  0.292695   \n",
       "\n",
       "                                    Diabetes_pedigree_function       Age  \\\n",
       "times_pregnant                                       -0.033523  0.544341   \n",
       "Plasma_glucose_concentration_2 hr                     0.137337  0.263514   \n",
       "blood_pressure                                        0.041265  0.239528   \n",
       " Triceps_skin_fold_thickness                          0.183928 -0.113970   \n",
       " Hr2_serum_insulin                                    0.185071 -0.042163   \n",
       "BOI                                                   0.140647  0.036242   \n",
       " Diabetes_pedigree_function                           1.000000  0.033561   \n",
       "Age                                                   0.033561  1.000000   \n",
       "Class                                                 0.173844  0.238356   \n",
       "\n",
       "                                      Class  \n",
       "times_pregnant                     0.221898  \n",
       "Plasma_glucose_concentration_2 hr  0.466581  \n",
       "blood_pressure                     0.065068  \n",
       " Triceps_skin_fold_thickness       0.074752  \n",
       " Hr2_serum_insulin                 0.130548  \n",
       "BOI                                0.292695  \n",
       " Diabetes_pedigree_function        0.173844  \n",
       "Age                                0.238356  \n",
       "Class                              1.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2908a2bfbe0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2908a28fba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2908a2f45f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['Age'], df['blood_pressure'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['Class'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>Plasma_glucose_concentration_2 hr</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>Triceps_skin_fold_thickness</th>\n",
       "      <th>Hr2_serum_insulin</th>\n",
       "      <th>BOI</th>\n",
       "      <th>Diabetes_pedigree_function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  Plasma_glucose_concentration_2 hr  blood_pressure  \\\n",
       "0             False                              False           False   \n",
       "1             False                              False           False   \n",
       "2             False                              False           False   \n",
       "3             False                              False           False   \n",
       "4             False                              False           False   \n",
       "5             False                              False           False   \n",
       "6             False                              False           False   \n",
       "7             False                              False           False   \n",
       "8             False                              False           False   \n",
       "9             False                              False           False   \n",
       "10            False                              False           False   \n",
       "11            False                              False           False   \n",
       "12            False                              False           False   \n",
       "13            False                              False           False   \n",
       "14            False                              False           False   \n",
       "15            False                              False           False   \n",
       "16            False                              False           False   \n",
       "17            False                              False           False   \n",
       "18            False                              False           False   \n",
       "19            False                              False           False   \n",
       "20            False                              False           False   \n",
       "21            False                              False           False   \n",
       "22            False                              False           False   \n",
       "23            False                              False           False   \n",
       "24            False                              False           False   \n",
       "25            False                              False           False   \n",
       "26            False                              False           False   \n",
       "27            False                              False           False   \n",
       "28            False                              False           False   \n",
       "29            False                              False           False   \n",
       "..              ...                                ...             ...   \n",
       "738           False                              False           False   \n",
       "739           False                              False           False   \n",
       "740           False                              False           False   \n",
       "741           False                              False           False   \n",
       "742           False                              False           False   \n",
       "743           False                              False           False   \n",
       "744           False                              False           False   \n",
       "745           False                              False           False   \n",
       "746           False                              False           False   \n",
       "747           False                              False           False   \n",
       "748           False                              False           False   \n",
       "749           False                              False           False   \n",
       "750           False                              False           False   \n",
       "751           False                              False           False   \n",
       "752           False                              False           False   \n",
       "753           False                              False           False   \n",
       "754           False                              False           False   \n",
       "755           False                              False           False   \n",
       "756           False                              False           False   \n",
       "757           False                              False           False   \n",
       "758           False                              False           False   \n",
       "759           False                              False           False   \n",
       "760           False                              False           False   \n",
       "761           False                              False           False   \n",
       "762           False                              False           False   \n",
       "763           False                              False           False   \n",
       "764           False                              False           False   \n",
       "765           False                              False           False   \n",
       "766           False                              False           False   \n",
       "767           False                              False           False   \n",
       "\n",
       "      Triceps_skin_fold_thickness    Hr2_serum_insulin    BOI  \\\n",
       "0                            False               False  False   \n",
       "1                            False               False  False   \n",
       "2                            False               False  False   \n",
       "3                            False               False  False   \n",
       "4                            False               False  False   \n",
       "5                            False               False  False   \n",
       "6                            False               False  False   \n",
       "7                            False               False  False   \n",
       "8                            False               False  False   \n",
       "9                            False               False  False   \n",
       "10                           False               False  False   \n",
       "11                           False               False  False   \n",
       "12                           False               False  False   \n",
       "13                           False               False  False   \n",
       "14                           False               False  False   \n",
       "15                           False               False  False   \n",
       "16                           False               False  False   \n",
       "17                           False               False  False   \n",
       "18                           False               False  False   \n",
       "19                           False               False  False   \n",
       "20                           False               False  False   \n",
       "21                           False               False  False   \n",
       "22                           False               False  False   \n",
       "23                           False               False  False   \n",
       "24                           False               False  False   \n",
       "25                           False               False  False   \n",
       "26                           False               False  False   \n",
       "27                           False               False  False   \n",
       "28                           False               False  False   \n",
       "29                           False               False  False   \n",
       "..                             ...                 ...    ...   \n",
       "738                          False               False  False   \n",
       "739                          False               False  False   \n",
       "740                          False               False  False   \n",
       "741                          False               False  False   \n",
       "742                          False               False  False   \n",
       "743                          False               False  False   \n",
       "744                          False               False  False   \n",
       "745                          False               False  False   \n",
       "746                          False               False  False   \n",
       "747                          False               False  False   \n",
       "748                          False               False  False   \n",
       "749                          False               False  False   \n",
       "750                          False               False  False   \n",
       "751                          False               False  False   \n",
       "752                          False               False  False   \n",
       "753                          False               False  False   \n",
       "754                          False               False  False   \n",
       "755                          False               False  False   \n",
       "756                          False               False  False   \n",
       "757                          False               False  False   \n",
       "758                          False               False  False   \n",
       "759                          False               False  False   \n",
       "760                          False               False  False   \n",
       "761                          False               False  False   \n",
       "762                          False               False  False   \n",
       "763                          False               False  False   \n",
       "764                          False               False  False   \n",
       "765                          False               False  False   \n",
       "766                          False               False  False   \n",
       "767                          False               False  False   \n",
       "\n",
       "      Diabetes_pedigree_function    Age  Class  \n",
       "0                          False  False  False  \n",
       "1                          False  False  False  \n",
       "2                          False  False  False  \n",
       "3                          False  False  False  \n",
       "4                          False  False  False  \n",
       "5                          False  False  False  \n",
       "6                          False  False  False  \n",
       "7                          False  False  False  \n",
       "8                          False  False  False  \n",
       "9                          False  False  False  \n",
       "10                         False  False  False  \n",
       "11                         False  False  False  \n",
       "12                         False  False  False  \n",
       "13                         False  False  False  \n",
       "14                         False  False  False  \n",
       "15                         False  False  False  \n",
       "16                         False  False  False  \n",
       "17                         False  False  False  \n",
       "18                         False  False  False  \n",
       "19                         False  False  False  \n",
       "20                         False  False  False  \n",
       "21                         False  False  False  \n",
       "22                         False  False  False  \n",
       "23                         False  False  False  \n",
       "24                         False  False  False  \n",
       "25                         False  False  False  \n",
       "26                         False  False  False  \n",
       "27                         False  False  False  \n",
       "28                         False  False  False  \n",
       "29                         False  False  False  \n",
       "..                           ...    ...    ...  \n",
       "738                        False  False  False  \n",
       "739                        False  False  False  \n",
       "740                        False  False  False  \n",
       "741                        False  False  False  \n",
       "742                        False  False  False  \n",
       "743                        False  False  False  \n",
       "744                        False  False  False  \n",
       "745                        False  False  False  \n",
       "746                        False  False  False  \n",
       "747                        False  False  False  \n",
       "748                        False  False  False  \n",
       "749                        False  False  False  \n",
       "750                        False  False  False  \n",
       "751                        False  False  False  \n",
       "752                        False  False  False  \n",
       "753                        False  False  False  \n",
       "754                        False  False  False  \n",
       "755                        False  False  False  \n",
       "756                        False  False  False  \n",
       "757                        False  False  False  \n",
       "758                        False  False  False  \n",
       "759                        False  False  False  \n",
       "760                        False  False  False  \n",
       "761                        False  False  False  \n",
       "762                        False  False  False  \n",
       "763                        False  False  False  \n",
       "764                        False  False  False  \n",
       "765                        False  False  False  \n",
       "766                        False  False  False  \n",
       "767                        False  False  False  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x2908a390a90>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x2908a3984e0>,\n",
       "  <matplotlib.lines.Line2D at 0x2908a398908>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x2908a3a1198>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x2908a398d30>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x2908a390be0>,\n",
       "  <matplotlib.lines.Line2D at 0x2908a3980b8>]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2908a29f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df['Age'], sym='gx', notch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x2908a3efda0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x2908a3f87f0>,\n",
       "  <matplotlib.lines.Line2D at 0x2908a3f8c18>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x2908a4024a8>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x2908a402080>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x2908a3efef0>,\n",
       "  <matplotlib.lines.Line2D at 0x2908a3f83c8>]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2908a3af9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df['Plasma_glucose_concentration_2 hr'], sym='gx', notch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 99.   117.   140.25]\n",
      "Float64Index([0.25, 0.5, 0.75], dtype='float64')\n",
      "99.0\n",
      "117.0\n",
      "140.25\n"
     ]
    }
   ],
   "source": [
    "x = df['Plasma_glucose_concentration_2 hr'].quantile([0.25,\n",
    "                                                      0.5,0.75])\n",
    "print(x.values)\n",
    "print(x.index)\n",
    "print(x[.25])\n",
    "print(x[.5])\n",
    "print(x[.75])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.875"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IQR = x[.75] - x[.25]\n",
    "print(IQR)\n",
    "\n",
    "IQR15 = 1.5*IQR\n",
    "IQR15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Whisker : 202.125\n",
      "Lower Whisker : 37.125\n"
     ]
    }
   ],
   "source": [
    "U_W = x[.75] + IQR15\n",
    "L_W = x[.25] - IQR15\n",
    "\n",
    "print(\"Upper Whisker :\", U_W)\n",
    "print(\"Lower Whisker :\", L_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Outliers\n",
      "Lower Outliers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75     0\n",
       "182    0\n",
       "342    0\n",
       "349    0\n",
       "502    0\n",
       "Name: Plasma_glucose_concentration_2 hr, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify outliers\n",
    "print(\"Upper Outliers\")\n",
    "df['Plasma_glucose_concentration_2 hr']\n",
    "[df['Plasma_glucose_concentration_2 hr'] > U_W]\n",
    "\n",
    "print(\"Lower Outliers\")\n",
    "df['Plasma_glucose_concentration_2 hr']\n",
    "[df['Plasma_glucose_concentration_2 hr'] < L_W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05     79.0\n",
       "0.95    181.0\n",
       "Name: Plasma_glucose_concentration_2 hr, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating 5 nad 95 percentile  \n",
    "cap = df['Plasma_glucose_concentration_2 hr'].quantile([0.05,0.95])\n",
    "cap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manish.khati\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Treat outlier with capping and flooring \n",
    "\n",
    "df['Plasma_glucose_concentration_2 hr']\n",
    "[df['Plasma_glucose_concentration_2 hr'] < L_W] = cap[.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Plasma_glucose_concentration_2 hr, dtype: int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Plasma_glucose_concentration_2 hr']\n",
    "[df['Plasma_glucose_concentration_2 hr'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "times_pregnant                        1.00\n",
       "Plasma_glucose_concentration_2 hr    79.00\n",
       "blood_pressure                       48.00\n",
       " Triceps_skin_fold_thickness         20.00\n",
       " Hr2_serum_insulin                    0.00\n",
       "BOI                                  24.70\n",
       " Diabetes_pedigree_function           0.14\n",
       "Age                                  22.00\n",
       "Class                                 0.00\n",
       "Name: 75, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x2908a2ff160>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x2908a2ffeb8>,\n",
       "  <matplotlib.lines.Line2D at 0x2908a296908>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x2908a3573c8>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x2908a29a438>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x2908a2ff358>,\n",
       "  <matplotlib.lines.Line2D at 0x2908a2ffc88>]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29089c6e080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df['Plasma_glucose_concentration_2 hr'], sym='gx', notch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.651042\n",
      "1    0.348958\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# target variable % distribution\n",
    "print(df['Class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build a quick logistic regression model and check the accuracy\n",
    "\n",
    "X = df.iloc[:,:8] # independent variables\n",
    "y = df['Class'] # dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate a logistic regression model, and fit\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict class labels for the train set. The predict fuction converts probability values > .5 to 1 else 0\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate class probabilities\n",
    "# Notice that 2 elements will be returned in probs array,\n",
    "\n",
    "probs = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10927859,  0.89072141],\n",
       "       [ 0.78972605,  0.21027395],\n",
       "       [ 0.85929963,  0.14070037],\n",
       "       [ 0.39128836,  0.60871164],\n",
       "       [ 0.8255974 ,  0.1744026 ],\n",
       "       [ 0.92353765,  0.07646235],\n",
       "       [ 0.32291251,  0.67708749],\n",
       "       [ 0.25669134,  0.74330866],\n",
       "       [ 0.59214541,  0.40785459],\n",
       "       [ 0.62429282,  0.37570718],\n",
       "       [ 0.45786141,  0.54213859],\n",
       "       [ 0.1044592 ,  0.8955408 ],\n",
       "       [ 0.69141999,  0.30858001],\n",
       "       [ 0.7763338 ,  0.2236662 ],\n",
       "       [ 0.83010808,  0.16989192],\n",
       "       [ 0.79492177,  0.20507823],\n",
       "       [ 0.19582735,  0.80417265],\n",
       "       [ 0.93029869,  0.06970131],\n",
       "       [ 0.59223701,  0.40776299],\n",
       "       [ 0.68591115,  0.31408885],\n",
       "       [ 0.42864491,  0.57135509],\n",
       "       [ 0.64675796,  0.35324204],\n",
       "       [ 0.64309567,  0.35690433],\n",
       "       [ 0.9036953 ,  0.0963047 ],\n",
       "       [ 0.89736227,  0.10263773],\n",
       "       [ 0.62023166,  0.37976834],\n",
       "       [ 0.91298827,  0.08701173],\n",
       "       [ 0.17810709,  0.82189291],\n",
       "       [ 0.82052122,  0.17947878],\n",
       "       [ 0.79428368,  0.20571632],\n",
       "       [ 0.52622367,  0.47377633],\n",
       "       [ 0.7213916 ,  0.2786084 ],\n",
       "       [ 0.87219639,  0.12780361],\n",
       "       [ 0.52874841,  0.47125159],\n",
       "       [ 0.81705159,  0.18294841],\n",
       "       [ 0.3377263 ,  0.6622737 ],\n",
       "       [ 0.52367941,  0.47632059],\n",
       "       [ 0.86912701,  0.13087299],\n",
       "       [ 0.59807671,  0.40192329],\n",
       "       [ 0.30428295,  0.69571705],\n",
       "       [ 0.69586516,  0.30413484],\n",
       "       [ 0.7858872 ,  0.2141128 ],\n",
       "       [ 0.76514396,  0.23485604],\n",
       "       [ 0.23706703,  0.76293297],\n",
       "       [ 0.27601201,  0.72398799],\n",
       "       [ 0.96562809,  0.03437191],\n",
       "       [ 0.84117169,  0.15882831],\n",
       "       [ 0.71594937,  0.28405063],\n",
       "       [ 0.62322191,  0.37677809],\n",
       "       [ 0.69504479,  0.30495521],\n",
       "       [ 0.55749578,  0.44250422],\n",
       "       [ 0.73760552,  0.26239448],\n",
       "       [ 0.19011977,  0.80988023],\n",
       "       [ 0.53559803,  0.46440197],\n",
       "       [ 0.82079379,  0.17920621],\n",
       "       [ 0.98741573,  0.01258427],\n",
       "       [ 0.8875292 ,  0.1124708 ],\n",
       "       [ 0.58893465,  0.41106535],\n",
       "       [ 0.69324164,  0.30675836],\n",
       "       [ 0.74394832,  0.25605168],\n",
       "       [ 0.36730702,  0.63269298],\n",
       "       [ 0.53267682,  0.46732318],\n",
       "       [ 0.83234712,  0.16765288],\n",
       "       [ 0.2815969 ,  0.7184031 ],\n",
       "       [ 0.3726847 ,  0.6273153 ],\n",
       "       [ 0.1623601 ,  0.8376399 ],\n",
       "       [ 0.36029727,  0.63970273],\n",
       "       [ 0.80412302,  0.19587698],\n",
       "       [ 0.59169181,  0.40830819],\n",
       "       [ 0.83918858,  0.16081142],\n",
       "       [ 0.81967979,  0.18032021],\n",
       "       [ 0.44720975,  0.55279025],\n",
       "       [ 0.85648869,  0.14351131],\n",
       "       [ 0.14312213,  0.85687787],\n",
       "       [ 0.25419269,  0.74580731],\n",
       "       [ 0.67701231,  0.32298769],\n",
       "       [ 0.86568801,  0.13431199],\n",
       "       [ 0.40564398,  0.59435602],\n",
       "       [ 0.89073124,  0.10926876],\n",
       "       [ 0.77335809,  0.22664191],\n",
       "       [ 0.67077545,  0.32922455],\n",
       "       [ 0.59961518,  0.40038482],\n",
       "       [ 0.75562622,  0.24437378],\n",
       "       [ 0.92028342,  0.07971658],\n",
       "       [ 0.7401714 ,  0.2598286 ],\n",
       "       [ 0.78267166,  0.21732834],\n",
       "       [ 0.64410799,  0.35589201],\n",
       "       [ 0.54073229,  0.45926771],\n",
       "       [ 0.2090163 ,  0.7909837 ],\n",
       "       [ 0.78782814,  0.21217186],\n",
       "       [ 0.77239018,  0.22760982],\n",
       "       [ 0.78718278,  0.21281722],\n",
       "       [ 0.7010004 ,  0.2989996 ],\n",
       "       [ 0.91892982,  0.08107018],\n",
       "       [ 0.41596588,  0.58403412],\n",
       "       [ 0.73851515,  0.26148485],\n",
       "       [ 0.60895467,  0.39104533],\n",
       "       [ 0.52933733,  0.47066267],\n",
       "       [ 0.46773456,  0.53226544],\n",
       "       [ 0.72152427,  0.27847573],\n",
       "       [ 0.7352068 ,  0.2647932 ],\n",
       "       [ 0.83548029,  0.16451971],\n",
       "       [ 0.7807759 ,  0.2192241 ],\n",
       "       [ 0.91557142,  0.08442858],\n",
       "       [ 0.4390371 ,  0.5609629 ],\n",
       "       [ 0.63970547,  0.36029453],\n",
       "       [ 0.82152404,  0.17847596],\n",
       "       [ 0.66152342,  0.33847658],\n",
       "       [ 0.91349106,  0.08650894],\n",
       "       [ 0.27980132,  0.72019868],\n",
       "       [ 0.83402541,  0.16597459],\n",
       "       [ 0.66092381,  0.33907619],\n",
       "       [ 0.41726913,  0.58273087],\n",
       "       [ 0.65812051,  0.34187949],\n",
       "       [ 0.48187829,  0.51812171],\n",
       "       [ 0.43938641,  0.56061359],\n",
       "       [ 0.82481335,  0.17518665],\n",
       "       [ 0.33213996,  0.66786004],\n",
       "       [ 0.85898979,  0.14101021],\n",
       "       [ 0.34326459,  0.65673541],\n",
       "       [ 0.63145637,  0.36854363],\n",
       "       [ 0.69477932,  0.30522068],\n",
       "       [ 0.66796469,  0.33203531],\n",
       "       [ 0.53097845,  0.46902155],\n",
       "       [ 0.72619779,  0.27380221],\n",
       "       [ 0.90341794,  0.09658206],\n",
       "       [ 0.69050041,  0.30949959],\n",
       "       [ 0.63384367,  0.36615633],\n",
       "       [ 0.52694453,  0.47305547],\n",
       "       [ 0.62094463,  0.37905537],\n",
       "       [ 0.57428149,  0.42571851],\n",
       "       [ 0.83644517,  0.16355483],\n",
       "       [ 0.88883466,  0.11116534],\n",
       "       [ 0.30409721,  0.69590279],\n",
       "       [ 0.66746273,  0.33253727],\n",
       "       [ 0.59750695,  0.40249305],\n",
       "       [ 0.78503939,  0.21496061],\n",
       "       [ 0.60488064,  0.39511936],\n",
       "       [ 0.29693819,  0.70306181],\n",
       "       [ 0.73331476,  0.26668524],\n",
       "       [ 0.85254385,  0.14745615],\n",
       "       [ 0.47188582,  0.52811418],\n",
       "       [ 0.87047909,  0.12952091],\n",
       "       [ 0.88678133,  0.11321867],\n",
       "       [ 0.63146561,  0.36853439],\n",
       "       [ 0.85382236,  0.14617764],\n",
       "       [ 0.8650449 ,  0.1349551 ],\n",
       "       [ 0.8439462 ,  0.1560538 ],\n",
       "       [ 0.8237131 ,  0.1762869 ],\n",
       "       [ 0.77246386,  0.22753614],\n",
       "       [ 0.85320098,  0.14679902],\n",
       "       [ 0.46713938,  0.53286062],\n",
       "       [ 0.83453965,  0.16546035],\n",
       "       [ 0.78265946,  0.21734054],\n",
       "       [ 0.31600886,  0.68399114],\n",
       "       [ 0.80678239,  0.19321761],\n",
       "       [ 0.41330422,  0.58669578],\n",
       "       [ 0.79454205,  0.20545795],\n",
       "       [ 0.35967255,  0.64032745],\n",
       "       [ 0.06695361,  0.93304639],\n",
       "       [ 0.34618537,  0.65381463],\n",
       "       [ 0.28133327,  0.71866673],\n",
       "       [ 0.93770393,  0.06229607],\n",
       "       [ 0.69421699,  0.30578301],\n",
       "       [ 0.20394624,  0.79605376],\n",
       "       [ 0.54616554,  0.45383446],\n",
       "       [ 0.73014079,  0.26985921],\n",
       "       [ 0.81645646,  0.18354354],\n",
       "       [ 0.69130033,  0.30869967],\n",
       "       [ 0.86964599,  0.13035401],\n",
       "       [ 0.78377486,  0.21622514],\n",
       "       [ 0.74550723,  0.25449277],\n",
       "       [ 0.76520772,  0.23479228],\n",
       "       [ 0.7502134 ,  0.2497866 ],\n",
       "       [ 0.51310088,  0.48689912],\n",
       "       [ 0.81912057,  0.18087943],\n",
       "       [ 0.62723812,  0.37276188],\n",
       "       [ 0.8507758 ,  0.1492242 ],\n",
       "       [ 0.82318537,  0.17681463],\n",
       "       [ 0.87873537,  0.12126463],\n",
       "       [ 0.80753242,  0.19246758],\n",
       "       [ 0.30564435,  0.69435565],\n",
       "       [ 0.81512333,  0.18487667],\n",
       "       [ 0.12839787,  0.87160213],\n",
       "       [ 0.54130768,  0.45869232],\n",
       "       [ 0.94243983,  0.05756017],\n",
       "       [ 0.31014895,  0.68985105],\n",
       "       [ 0.70286151,  0.29713849],\n",
       "       [ 0.54124547,  0.45875453],\n",
       "       [ 0.81514038,  0.18485962],\n",
       "       [ 0.75843945,  0.24156055],\n",
       "       [ 0.85466539,  0.14533461],\n",
       "       [ 0.84488969,  0.15511031],\n",
       "       [ 0.71051218,  0.28948782],\n",
       "       [ 0.88075621,  0.11924379],\n",
       "       [ 0.27690216,  0.72309784],\n",
       "       [ 0.31386417,  0.68613583],\n",
       "       [ 0.49730795,  0.50269205],\n",
       "       [ 0.87822967,  0.12177033],\n",
       "       [ 0.69840754,  0.30159246],\n",
       "       [ 0.86961677,  0.13038323],\n",
       "       [ 0.79262011,  0.20737989],\n",
       "       [ 0.76343622,  0.23656378],\n",
       "       [ 0.60836888,  0.39163112],\n",
       "       [ 0.7176765 ,  0.2823235 ],\n",
       "       [ 0.80565245,  0.19434755],\n",
       "       [ 0.73316523,  0.26683477],\n",
       "       [ 0.78141224,  0.21858776],\n",
       "       [ 0.60816757,  0.39183243],\n",
       "       [ 0.81227026,  0.18772974],\n",
       "       [ 0.8614662 ,  0.1385338 ],\n",
       "       [ 0.86718409,  0.13281591],\n",
       "       [ 0.64292765,  0.35707235],\n",
       "       [ 0.65264333,  0.34735667],\n",
       "       [ 0.75141086,  0.24858914],\n",
       "       [ 0.66434613,  0.33565387],\n",
       "       [ 0.53062071,  0.46937929],\n",
       "       [ 0.66292099,  0.33707901],\n",
       "       [ 0.46941441,  0.53058559],\n",
       "       [ 0.75534171,  0.24465829],\n",
       "       [ 0.81583236,  0.18416764],\n",
       "       [ 0.90430254,  0.09569746],\n",
       "       [ 0.59232393,  0.40767607],\n",
       "       [ 0.41446952,  0.58553048],\n",
       "       [ 0.48318088,  0.51681912],\n",
       "       [ 0.34831506,  0.65168494],\n",
       "       [ 0.7254485 ,  0.2745515 ],\n",
       "       [ 0.70155369,  0.29844631],\n",
       "       [ 0.89273365,  0.10726635],\n",
       "       [ 0.80289605,  0.19710395],\n",
       "       [ 0.55771498,  0.44228502]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st element is probability for negative class,\n",
    "# 2nd element gives probability for positive class\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89072141,  0.21027395,  0.14070037,  0.60871164,  0.1744026 ,\n",
       "        0.07646235,  0.67708749,  0.74330866,  0.40785459,  0.37570718,\n",
       "        0.54213859,  0.8955408 ,  0.30858001,  0.2236662 ,  0.16989192,\n",
       "        0.20507823,  0.80417265,  0.06970131,  0.40776299,  0.31408885,\n",
       "        0.57135509,  0.35324204,  0.35690433,  0.0963047 ,  0.10263773,\n",
       "        0.37976834,  0.08701173,  0.82189291,  0.17947878,  0.20571632,\n",
       "        0.47377633,  0.2786084 ,  0.12780361,  0.47125159,  0.18294841,\n",
       "        0.6622737 ,  0.47632059,  0.13087299,  0.40192329,  0.69571705,\n",
       "        0.30413484,  0.2141128 ,  0.23485604,  0.76293297,  0.72398799,\n",
       "        0.03437191,  0.15882831,  0.28405063,  0.37677809,  0.30495521,\n",
       "        0.44250422,  0.26239448,  0.80988023,  0.46440197,  0.17920621,\n",
       "        0.01258427,  0.1124708 ,  0.41106535,  0.30675836,  0.25605168,\n",
       "        0.63269298,  0.46732318,  0.16765288,  0.7184031 ,  0.6273153 ,\n",
       "        0.8376399 ,  0.63970273,  0.19587698,  0.40830819,  0.16081142,\n",
       "        0.18032021,  0.55279025,  0.14351131,  0.85687787,  0.74580731,\n",
       "        0.32298769,  0.13431199,  0.59435602,  0.10926876,  0.22664191,\n",
       "        0.32922455,  0.40038482,  0.24437378,  0.07971658,  0.2598286 ,\n",
       "        0.21732834,  0.35589201,  0.45926771,  0.7909837 ,  0.21217186,\n",
       "        0.22760982,  0.21281722,  0.2989996 ,  0.08107018,  0.58403412,\n",
       "        0.26148485,  0.39104533,  0.47066267,  0.53226544,  0.27847573,\n",
       "        0.2647932 ,  0.16451971,  0.2192241 ,  0.08442858,  0.5609629 ,\n",
       "        0.36029453,  0.17847596,  0.33847658,  0.08650894,  0.72019868,\n",
       "        0.16597459,  0.33907619,  0.58273087,  0.34187949,  0.51812171,\n",
       "        0.56061359,  0.17518665,  0.66786004,  0.14101021,  0.65673541,\n",
       "        0.36854363,  0.30522068,  0.33203531,  0.46902155,  0.27380221,\n",
       "        0.09658206,  0.30949959,  0.36615633,  0.47305547,  0.37905537,\n",
       "        0.42571851,  0.16355483,  0.11116534,  0.69590279,  0.33253727,\n",
       "        0.40249305,  0.21496061,  0.39511936,  0.70306181,  0.26668524,\n",
       "        0.14745615,  0.52811418,  0.12952091,  0.11321867,  0.36853439,\n",
       "        0.14617764,  0.1349551 ,  0.1560538 ,  0.1762869 ,  0.22753614,\n",
       "        0.14679902,  0.53286062,  0.16546035,  0.21734054,  0.68399114,\n",
       "        0.19321761,  0.58669578,  0.20545795,  0.64032745,  0.93304639,\n",
       "        0.65381463,  0.71866673,  0.06229607,  0.30578301,  0.79605376,\n",
       "        0.45383446,  0.26985921,  0.18354354,  0.30869967,  0.13035401,\n",
       "        0.21622514,  0.25449277,  0.23479228,  0.2497866 ,  0.48689912,\n",
       "        0.18087943,  0.37276188,  0.1492242 ,  0.17681463,  0.12126463,\n",
       "        0.19246758,  0.69435565,  0.18487667,  0.87160213,  0.45869232,\n",
       "        0.05756017,  0.68985105,  0.29713849,  0.45875453,  0.18485962,\n",
       "        0.24156055,  0.14533461,  0.15511031,  0.28948782,  0.11924379,\n",
       "        0.72309784,  0.68613583,  0.50269205,  0.12177033,  0.30159246,\n",
       "        0.13038323,  0.20737989,  0.23656378,  0.39163112,  0.2823235 ,\n",
       "        0.19434755,  0.26683477,  0.21858776,  0.39183243,  0.18772974,\n",
       "        0.1385338 ,  0.13281591,  0.35707235,  0.34735667,  0.24858914,\n",
       "        0.33565387,  0.46937929,  0.33707901,  0.53058559,  0.24465829,\n",
       "        0.18416764,  0.09569746,  0.40767607,  0.58553048,  0.51681912,\n",
       "        0.65168494,  0.2745515 ,  0.29844631,  0.10726635,  0.19710395,\n",
       "        0.44228502])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability for positive class\n",
    "y_pred_prob = probs[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.78354978355\n"
     ]
    }
   ],
   "source": [
    "# generate evaluation metrics\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve : 0.838785\n"
     ]
    }
   ],
   "source": [
    "# extract false positive, true positive rate\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1-fpr       fpr       tpr\n",
      "0   1.000000  0.000000  0.013514\n",
      "1   1.000000  0.000000  0.054054\n",
      "2   0.993631  0.006369  0.054054\n",
      "3   0.993631  0.006369  0.067568\n",
      "4   0.987261  0.012739  0.067568\n",
      "5   0.987261  0.012739  0.094595\n",
      "6   0.980892  0.019108  0.094595\n",
      "7   0.980892  0.019108  0.243243\n",
      "8   0.974522  0.025478  0.243243\n",
      "9   0.974522  0.025478  0.310811\n",
      "10  0.968153  0.031847  0.310811\n",
      "11  0.968153  0.031847  0.351351\n",
      "12  0.961783  0.038217  0.351351\n",
      "13  0.961783  0.038217  0.418919\n",
      "14  0.949045  0.050955  0.418919\n",
      "15  0.949045  0.050955  0.432432\n",
      "16  0.942675  0.057325  0.432432\n",
      "17  0.942675  0.057325  0.459459\n",
      "18  0.936306  0.063694  0.459459\n",
      "19  0.936306  0.063694  0.472973\n",
      "20  0.929936  0.070064  0.472973\n",
      "21  0.929936  0.070064  0.513514\n",
      "22  0.917197  0.082803  0.513514\n",
      "23  0.917197  0.082803  0.527027\n",
      "24  0.898089  0.101911  0.527027\n",
      "25  0.898089  0.101911  0.540541\n",
      "26  0.872611  0.127389  0.540541\n",
      "27  0.872611  0.127389  0.554054\n",
      "28  0.847134  0.152866  0.554054\n",
      "29  0.847134  0.152866  0.594595\n",
      "..       ...       ...       ...\n",
      "43  0.745223  0.254777  0.756757\n",
      "44  0.738854  0.261146  0.756757\n",
      "45  0.738854  0.261146  0.783784\n",
      "46  0.732484  0.267516  0.783784\n",
      "47  0.732484  0.267516  0.797297\n",
      "48  0.675159  0.324841  0.797297\n",
      "49  0.675159  0.324841  0.810811\n",
      "50  0.662420  0.337580  0.810811\n",
      "51  0.662420  0.337580  0.824324\n",
      "52  0.643312  0.356688  0.824324\n",
      "53  0.643312  0.356688  0.851351\n",
      "54  0.636943  0.363057  0.851351\n",
      "55  0.636943  0.363057  0.878378\n",
      "56  0.630573  0.369427  0.878378\n",
      "57  0.630573  0.369427  0.905405\n",
      "58  0.579618  0.420382  0.905405\n",
      "59  0.579618  0.420382  0.918919\n",
      "60  0.573248  0.426752  0.918919\n",
      "61  0.573248  0.426752  0.932432\n",
      "62  0.535032  0.464968  0.932432\n",
      "63  0.535032  0.464968  0.945946\n",
      "64  0.528662  0.471338  0.945946\n",
      "65  0.528662  0.471338  0.959459\n",
      "66  0.401274  0.598726  0.959459\n",
      "67  0.401274  0.598726  0.972973\n",
      "68  0.382166  0.617834  0.972973\n",
      "69  0.382166  0.617834  0.986486\n",
      "70  0.197452  0.802548  0.986486\n",
      "71  0.197452  0.802548  1.000000\n",
      "72  0.000000  1.000000  1.000000\n",
      "\n",
      "[73 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr,\n",
    "index = i),'1-fpr' : pd.Series(1-fpr, index = i)})\n",
    "\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Which Error is Costly??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rare Event or Imbalanced Dataset\n",
    "\n",
    "Providing an equal samples of positive and negative instances to the classification algorithm will result in an optimal result. Datasets that are highly skewed toward one or more classes have proven to be a challenge.\n",
    "\n",
    "Resampling is a common practice to address the imbalanced dataset issue.\n",
    "\n",
    "#Random under-sampling - Reduce majority class to match minority class count.\n",
    "\n",
    "#Random over-sampling - Increase minority class by randomly picking samples within minority class till counts of both class match.\n",
    "\n",
    "#Synthetic Minority Over-Sampling Technique (SMOTE) - Increase minority class by introducing synthetic examples through connecting all k (default = 5) minority class nearest neighbors using feature space similarity (Euclidean distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias and Variance\n",
    "A fundamental problem with supervised learning is the bias variance trade-off. Ideally a model should have two key characteristics.\n",
    "1. Sensitive enough to accurately capture the key patterns in the training dataset.\n",
    "2. It should be generalized enough to work well on any unseen datasets.\n",
    "Unfortunately, while trying to achieve the above-mentioned first point, there is an ample chance of over-fitting to noisy or unrepresentative training data points leading to a failure of generalizing the model. On the other hand, trying to generalize a model may result in failing to capture important regularities.\n",
    "\n",
    "### Bias\n",
    "If model accuracy is low on a training dataset as well as test dataset the model is said to be under-fitting or that the model has high bias. This means the model is not fitting the training dataset points well in regression or the decision boundary is not separating the classes well in classification; and two key reasons for bias are 1) not including the right features, and 2) not picking the correct order of polynomial degrees for model fitting.\n",
    "\n",
    "To solve an under-fitting issue or to reduced bias, try including more meaningful features and try to increase the model complexity by trying higher-order polynomial fittings.\n",
    "\n",
    "### Variance\n",
    "If a model is giving high accuracy on a training dataset, however on a test dataset the accuracy drops drastically, then the model is said to be over-fitting or a model that has high variance. The key reason for over-fitting is using higher-order polynomial degree (may not be required), which will fit decision boundary tools well to all data points including the noise of train dataset, instead of the underlying relationship. This will lead to a high accuracy (actual vs. predicted) in the train dataset and when applied to the test dataset, the prediction error will be high.\n",
    "To solve the over-fitting issue:\n",
    "\n",
    "#Try to reduce the number of features, that is, keep only the meaningful features.\n",
    "#Dimension reduction can eliminate noisy features, in turn, reducing the model variance.\n",
    "#Brining more data points to make training dataset large will also reduce variance.\n",
    "#Choosing right model parameters can help to reduce the bias and variance, for example.\n",
    "   #Using right regularization parameters can decrease variance in regression-based models.\n",
    "   #For a decision tree reducing the depth of the decision tree will reduce the variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation\n",
    "\n",
    "K-folds cross-validation splits the training dataset into k-folds without replacement, that is, any given data point will only be part of one of the subset, where k-1 folds are used for the model training and one fold is used for testing. The procedure is repeated k times so that we obtain k models and performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = df.iloc[:,:8].values # independent variables\n",
    "y = df['Class'].values # dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "from sklearn import preprocessing\n",
    "sc = preprocessing.StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a decision tree classifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "clf = tree.DecisionTreeClassifier(random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold AUC Scores:  [ 0.7037037   0.63888889  0.65420561  0.6635514   0.71028037]\n",
      "Train CV AUC Score:  0.674125995154\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "train_scores = cross_val_score(clf, X_train, y_train, \n",
    "                               scoring='accuracy', cv=5)\n",
    "test_scores = cross_val_score(clf, X_test, y_test, \n",
    "                              scoring='accuracy', cv=5)\n",
    "print(\"Train Fold AUC Scores: \", train_scores)\n",
    "print(\"Train CV AUC Score: \", train_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Fold AUC Scores:  [ 0.70212766  0.74468085  0.74468085  0.64444444  0.66666667]\n",
      "Test CV AUC Score:  0.700520094563\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest Fold AUC Scores: \", test_scores)\n",
    "print(\"Test CV AUC Score: \", test_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified K-Fold Cross-Validation\n",
    "An extended cross-validation is the Stratified K-fold cross-validation, where the class proportions are preserved in each fold, leading to better\n",
    "bias and variance estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods\n",
    "Ensemble methods enable combining multiple model scores into a single score to create a robust generalized model.\n",
    "At a high level there are two types of ensemble methods.\n",
    "1. Combine multiple models of similar type\n",
    "     #### Bagging (Bootstrap aggregation)\n",
    "        Bootstrap aggregation (also known as bagging) was proposed by Leo Breiman in 1994, which is a model aggregation technique to reduce model variance. The training data is split into multiple samples with replacements called bootstrap samples. Bootstrap sample size will be the same as the original sample size, with 3/4th of the original values and replacement result in repetition of values\n",
    "     \n",
    "         Independent models on each of the bootstrap samples are built, and the average of the predictions for regression or majority vote for classification is used to create the final model.\n",
    " \n",
    "         Random Forest\n",
    "         \n",
    "     #### Boosting\n",
    "         The core concept of boosting is that rather than an independent individual hypothesis, combining hypotheses in a sequential order increases the accuracy. Essentially, boosting algorithms convert the weak learners into strong learners. Boosting algorithms are well designed to address the bias problems.\n",
    "         \n",
    "         At a high level the AdaBoosting (adaptive boosting) process can be divided into three steps.\n",
    "         1. Assign uniform weights for all data points W0(x) = 1 / N, where N is the total number of training data points.\n",
    "         2. At each iteration fit a classifier ym(xn) to the training data and update weights to minimize the weighted error function.\n",
    "         3. The final model.\n",
    "         \n",
    "         \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

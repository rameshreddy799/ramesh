{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine learning is the science of getting computers to act without being explicitly programmed.',\n",
       " 'In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine', 'learning', 'is', 'the']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming and lemmatization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "ls = nltk.LancasterStemmer()\n",
    "wl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavior\n",
      "behavy\n",
      "behavior\n"
     ]
    }
   ],
   "source": [
    "word = \"behaviors\"\n",
    "print(ps.stem(word))\n",
    "print(ls.stem(word))\n",
    "print(wl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behav\n",
      "behav\n",
      "behaving\n"
     ]
    }
   ],
   "source": [
    "word = \"behaving\"\n",
    "print(ps.stem(word))\n",
    "print(ls.stem(word))\n",
    "print(wl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed = [ ls.stem(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machin',\n",
       " 'learn',\n",
       " 'is',\n",
       " 'the',\n",
       " 'sci',\n",
       " 'of',\n",
       " 'get',\n",
       " 'comput',\n",
       " 'to',\n",
       " 'act',\n",
       " 'without',\n",
       " 'being',\n",
       " 'explicit',\n",
       " 'program',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'decad',\n",
       " ',',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'has',\n",
       " 'giv',\n",
       " 'us',\n",
       " 'self-driving',\n",
       " 'car',\n",
       " ',',\n",
       " 'pract',\n",
       " 'speech',\n",
       " 'recognit',\n",
       " ',',\n",
       " 'effect',\n",
       " 'web',\n",
       " 'search',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'vast',\n",
       " 'improv',\n",
       " 'understand',\n",
       " 'of',\n",
       " 'the',\n",
       " 'hum',\n",
       " 'genom',\n",
       " '.',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'is',\n",
       " 'so',\n",
       " 'pervas',\n",
       " 'today',\n",
       " 'that',\n",
       " 'you',\n",
       " 'prob',\n",
       " 'us',\n",
       " 'it',\n",
       " 'doz',\n",
       " 'of',\n",
       " 'tim',\n",
       " 'a',\n",
       " 'day',\n",
       " 'without',\n",
       " 'know',\n",
       " 'it',\n",
       " '.',\n",
       " 'many',\n",
       " 'research',\n",
       " 'also',\n",
       " 'think',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'way',\n",
       " 'to',\n",
       " 'mak',\n",
       " 'progress',\n",
       " 'toward',\n",
       " 'human-level',\n",
       " 'ai',\n",
       " '.',\n",
       " 'in',\n",
       " 'thi',\n",
       " 'class',\n",
       " ',',\n",
       " 'you',\n",
       " 'wil',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'the',\n",
       " 'most',\n",
       " 'effect',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'techn',\n",
       " ',',\n",
       " 'and',\n",
       " 'gain',\n",
       " 'pract',\n",
       " 'impl',\n",
       " 'them',\n",
       " 'and',\n",
       " 'get',\n",
       " 'them',\n",
       " 'to',\n",
       " 'work',\n",
       " 'for',\n",
       " 'yourself',\n",
       " '.',\n",
       " 'mor',\n",
       " 'import',\n",
       " ',',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'learn',\n",
       " 'about',\n",
       " 'not',\n",
       " 'on',\n",
       " 'the',\n",
       " 'theoret',\n",
       " 'underpin',\n",
       " 'of',\n",
       " 'learn',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'gain',\n",
       " 'the',\n",
       " 'pract',\n",
       " 'know-how',\n",
       " 'nee',\n",
       " 'to',\n",
       " 'quick',\n",
       " 'and',\n",
       " 'pow',\n",
       " 'apply',\n",
       " 'thes',\n",
       " 'techn',\n",
       " 'to',\n",
       " 'new',\n",
       " 'problem',\n",
       " '.',\n",
       " 'fin',\n",
       " ',',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'learn',\n",
       " 'about',\n",
       " 'som',\n",
       " 'of',\n",
       " 'silicon',\n",
       " 'valley',\n",
       " \"'s\",\n",
       " 'best',\n",
       " 'pract',\n",
       " 'in',\n",
       " 'innov',\n",
       " 'as',\n",
       " 'it',\n",
       " 'pertain',\n",
       " 'to',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'and',\n",
       " 'ai',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = [ lm.lemmatize(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'the',\n",
       " 'science',\n",
       " 'of',\n",
       " 'getting',\n",
       " 'computer',\n",
       " 'to',\n",
       " 'act',\n",
       " 'without',\n",
       " 'being',\n",
       " 'explicitly',\n",
       " 'programmed',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'past',\n",
       " 'decade',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'ha',\n",
       " 'given',\n",
       " 'u',\n",
       " 'self-driving',\n",
       " 'car',\n",
       " ',',\n",
       " 'practical',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'effective',\n",
       " 'web',\n",
       " 'search',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'vastly',\n",
       " 'improved',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'the',\n",
       " 'human',\n",
       " 'genome',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'so',\n",
       " 'pervasive',\n",
       " 'today',\n",
       " 'that',\n",
       " 'you',\n",
       " 'probably',\n",
       " 'use',\n",
       " 'it',\n",
       " 'dozen',\n",
       " 'of',\n",
       " 'time',\n",
       " 'a',\n",
       " 'day',\n",
       " 'without',\n",
       " 'knowing',\n",
       " 'it',\n",
       " '.',\n",
       " 'Many',\n",
       " 'researcher',\n",
       " 'also',\n",
       " 'think',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'way',\n",
       " 'to',\n",
       " 'make',\n",
       " 'progress',\n",
       " 'towards',\n",
       " 'human-level',\n",
       " 'AI',\n",
       " '.',\n",
       " 'In',\n",
       " 'this',\n",
       " 'class',\n",
       " ',',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'the',\n",
       " 'most',\n",
       " 'effective',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'technique',\n",
       " ',',\n",
       " 'and',\n",
       " 'gain',\n",
       " 'practice',\n",
       " 'implementing',\n",
       " 'them',\n",
       " 'and',\n",
       " 'getting',\n",
       " 'them',\n",
       " 'to',\n",
       " 'work',\n",
       " 'for',\n",
       " 'yourself',\n",
       " '.',\n",
       " 'More',\n",
       " 'importantly',\n",
       " ',',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'learn',\n",
       " 'about',\n",
       " 'not',\n",
       " 'only',\n",
       " 'the',\n",
       " 'theoretical',\n",
       " 'underpinnings',\n",
       " 'of',\n",
       " 'learning',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'gain',\n",
       " 'the',\n",
       " 'practical',\n",
       " 'know-how',\n",
       " 'needed',\n",
       " 'to',\n",
       " 'quickly',\n",
       " 'and',\n",
       " 'powerfully',\n",
       " 'apply',\n",
       " 'these',\n",
       " 'technique',\n",
       " 'to',\n",
       " 'new',\n",
       " 'problem',\n",
       " '.',\n",
       " 'Finally',\n",
       " ',',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'learn',\n",
       " 'about',\n",
       " 'some',\n",
       " 'of',\n",
       " 'Silicon',\n",
       " 'Valley',\n",
       " \"'s\",\n",
       " 'best',\n",
       " 'practice',\n",
       " 'in',\n",
       " 'innovation',\n",
       " 'a',\n",
       " 'it',\n",
       " 'pertains',\n",
       " 'to',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'AI',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine', 'learning', 'is', 'the', 'science']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "postags = pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'DT'), ('p', 'NN'), ('p', 'NN'), ('l', 'NN'), ('e', 'NN')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('science', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('getting', 'VBG'),\n",
       " ('computers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('act', 'VB'),\n",
       " ('without', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('explicitly', 'RB'),\n",
       " ('programmed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('past', 'JJ'),\n",
       " ('decade', 'NN'),\n",
       " (',', ',')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postags[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset(\"JJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = \"Google Incorporation Pvt Limited is starting a new office at Hyderabad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = word_tokenize(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagged = pos_tag(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Google', 'NNP'),\n",
       " ('Incorporation', 'NNP'),\n",
       " ('Pvt', 'NNP'),\n",
       " ('Limited', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('starting', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('office', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('Hyderabad', 'NNP')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [a[0] for a in tagged if a[1][1] == 'NNP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download NER for windows from : https://pypi.python.org/pypi/ner/0.1#downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" google chief is visiting india during the month of may, they are going to setup a new R&D facility at hyderabad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/visa'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.chdir(\"**New Directory**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Google', 'Sundar Pichai', 'India', 'Hyderabad', 'Apple Incorporation Limited', 'Facebook Inc', 'Mark', 'CEO', 'Hitex Convention']\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "with open('sample.txt', 'r') as f:\n",
    "    sample = f.read()\n",
    "\n",
    "\n",
    "sentences = nltk.sent_tokenize(sample)\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n",
    "\n",
    "def extract_entity_names(t):\n",
    "    entity_names = []\n",
    "\n",
    "    if hasattr(t, 'label') and t.label:\n",
    "        if t.label() == 'NE':\n",
    "            entity_names.append(' '.join([child[0] for child in t]))\n",
    "        else:\n",
    "            for child in t:\n",
    "                entity_names.extend(extract_entity_names(child))\n",
    "\n",
    "    return entity_names\n",
    "\n",
    "entity_names = []\n",
    "for tree in chunked_sentences:\n",
    "    # Print results per sentence\n",
    "    # print extract_entity_names(tree)\n",
    "\n",
    "    entity_names.extend(extract_entity_names(tree))\n",
    "\n",
    "# Print all entity names\n",
    "#print entity_names\n",
    "\n",
    "# Print unique entity names\n",
    "print (entity_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google chief is visiting india during the month of may, they are going to setup a new R&D facility at hyderabad\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    print sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download NER tagger from : https://nlp.stanford.edu/software/CRF-NER.shtml#Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visa/.local/lib/python3.5/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "st = StanfordNERTagger('/home/visa/stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "\t\t\t\t\t   '/home/visa/stanford-ner/stanford-ner.jar',\n",
    "\t\t\t\t\t   encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CEO', 'O'), ('of', 'O'), ('Microsoft', 'ORGANIZATION'), ('Satya', 'PERSON'), ('Nadella', 'PERSON'), ('is', 'O'), ('visiting', 'O'), ('India', 'LOCATION'), ('in', 'O'), ('2018', 'O'), (',', 'O'), ('as', 'O'), ('part', 'O'), ('of', 'O'), ('expansion', 'O'), ('will', 'O'), ('start', 'O'), ('a', 'O'), ('new', 'O'), ('R', 'O'), ('&', 'O'), ('D', 'O'), ('faility', 'O'), ('at', 'O'), ('Hyderabad', 'LOCATION'), ('.', 'O'), ('Google', 'ORGANIZATION'), ('will', 'O'), ('be', 'O'), ('competing', 'O'), ('with', 'O'), ('Apple', 'ORGANIZATION'), ('inc', 'ORGANIZATION'), ('.', 'O')]\n",
      "[('TCS', 'ORGANIZATION'), ('India', 'ORGANIZATION'), ('Pvt', 'ORGANIZATION'), ('Ltd', 'ORGANIZATION'), ('is', 'O'), ('expanding', 'O'), ('offices', 'O'), ('in', 'O'), ('India', 'LOCATION'), (',', 'O'), ('Will', 'O'), ('recruit', 'O'), ('freshers', 'O'), ('from', 'O'), ('top', 'O'), ('tier', 'O'), ('colleges', 'O')]\n"
     ]
    }
   ],
   "source": [
    "text = 'CEO of Microsoft Satya Nadella is visiting India in 2018, as part of expansion will start a new R&D faility at Hyderabad. Google will be competing with Apple inc.'\n",
    "text2 = 'TCS India Pvt Ltd is expanding offices in India, Will recruit freshers from top tier colleges'\n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "tokenized_text2 = word_tokenize(text2)\n",
    "classified_text2 = st.tag(tokenized_text2)\n",
    "\n",
    "print(classified_text)\n",
    "print(classified_text2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling in python - data source is a textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8 \n",
    "#encoding=utf-8\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk \n",
    "import unicodedata\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set working directory ( only if not using a vitual environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/visa/Topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "f = open(\"polarity_pos.txt\", \"r+\", encoding=\"latin1\")\n",
    "txt = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd = pd.DataFrame(txt, columns=[\"comments\"])\n",
    "imd[\"row\"] = imd.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  row\n",
       "0  the rock is destined to be the 21st century's ...    0\n",
       "1  the gorgeously elaborate continuation of \" the...    1\n",
       "2                   effective but too-tepid biopic\\n    2\n",
       "3  if you sometimes like to go to the movies to h...    3\n",
       "4  emerges as something rare , an issue movie tha...    4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "extended_stopwords = ['\\'ll','\\'d','\\'m','\\'re','\\'s','\\'ve','ca n\\'t','r','n\\'t','ca','see','get','movies','movie','go','say','come','many','another','could','would','made','really','want','even','odd','films','plot','ever','actually','also','movie','film']\n",
    "stops = stop_words + extended_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check with stemming and lemmatization to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'test', 'for', 'stemmer', 'and', 'stemming']\n"
     ]
    }
   ],
   "source": [
    "text = \" this is a test for stemmer and stemming \"\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "stm = PorterStemmer()\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "#tokens = [stm.stem(w) for w in tokens]\n",
    "tokens = [lemm.lemmatize(w) for w in tokens]\n",
    "#tokens = lemm.lemmatize(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to tokenize and lemmatize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    stm = PorterStemmer()\n",
    "    lemm = WordNetLemmatizer()\n",
    "    #tokens = [stm.stem(w) for w in tokens]\n",
    "    tokens = [lemm.lemmatize(w) for w in tokens]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setiment Analysis with textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd['polarity'] = imd.comments.apply(lambda s: TextBlob(s).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>row</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>a terrible movie that some people will neverth...</td>\n",
       "      <td>10657</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>there are many definitions of 'time waster' bu...</td>\n",
       "      <td>10658</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>as it stands , crocodile hunter has the hurrie...</td>\n",
       "      <td>10659</td>\n",
       "      <td>-0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>the thing looks like a made-for-home-video qui...</td>\n",
       "      <td>10660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>enigma is well-made , but it's just too dry an...</td>\n",
       "      <td>10661</td>\n",
       "      <td>-0.183333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments    row  polarity\n",
       "10657  a terrible movie that some people will neverth...  10657 -1.000000\n",
       "10658  there are many definitions of 'time waster' bu...  10658  0.500000\n",
       "10659  as it stands , crocodile hunter has the hurrie...  10659 -0.350000\n",
       "10660  the thing looks like a made-for-home-video qui...  10660  0.000000\n",
       "10661  enigma is well-made , but it's just too dry an...  10661 -0.183333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imd.head()\n",
    "imd.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document term matrix with TF-IDF values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.48 s, sys: 3.97 ms, total: 4.48 s\n",
      "Wall time: 4.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10662, 268)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_idf_vectorizer       = TfidfVectorizer(max_df=0.99, max_features=2000,min_df=0.005, stop_words=stops, use_idf=True, tokenizer=tokenize, ngram_range=(1,1))\n",
    "%time term_idf_matrix     = term_idf_vectorizer.fit_transform(imd.comments) \n",
    "term_idf_feature_names    = term_idf_vectorizer.get_feature_names()\n",
    "term_idf_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acting',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'almost',\n",
       " 'although',\n",
       " 'always',\n",
       " 'american',\n",
       " 'amusing',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'around',\n",
       " 'art',\n",
       " 'attempt',\n",
       " 'audience',\n",
       " 'away',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'becomes',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'book',\n",
       " 'boring',\n",
       " 'boy',\n",
       " 'care',\n",
       " 'cast',\n",
       " 'certainly',\n",
       " 'character',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'child',\n",
       " 'cinema',\n",
       " 'cinematic',\n",
       " 'classic',\n",
       " 'clever',\n",
       " 'comedy',\n",
       " 'comic',\n",
       " 'compelling',\n",
       " 'culture',\n",
       " 'dark',\n",
       " 'day',\n",
       " 'de',\n",
       " 'debut',\n",
       " 'despite',\n",
       " 'dialogue',\n",
       " 'direction',\n",
       " 'director',\n",
       " 'documentary',\n",
       " 'doe',\n",
       " 'done',\n",
       " 'drama',\n",
       " 'dull',\n",
       " 'easy',\n",
       " 'effect',\n",
       " 'effort',\n",
       " 'else',\n",
       " 'emotional',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'engaging',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enough',\n",
       " 'entertaining',\n",
       " 'entertainment',\n",
       " 'especially',\n",
       " 'every',\n",
       " 'everything',\n",
       " 'exercise',\n",
       " 'experience',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'fall',\n",
       " 'familiar',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'far',\n",
       " 'fascinating',\n",
       " 'feature',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'filmmaker',\n",
       " 'find',\n",
       " 'first',\n",
       " 'flick',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'genre',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'going',\n",
       " 'good',\n",
       " 'great',\n",
       " 'guy',\n",
       " 'ha',\n",
       " 'half',\n",
       " 'hard',\n",
       " 'heart',\n",
       " 'high',\n",
       " 'history',\n",
       " 'hollywood',\n",
       " 'home',\n",
       " 'horror',\n",
       " 'hour',\n",
       " 'human',\n",
       " 'humor',\n",
       " 'idea',\n",
       " 'instead',\n",
       " 'intelligent',\n",
       " 'interest',\n",
       " 'interesting',\n",
       " 'john',\n",
       " 'joke',\n",
       " 'keep',\n",
       " 'kid',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'lack',\n",
       " 'last',\n",
       " 'laugh',\n",
       " 'le',\n",
       " 'lead',\n",
       " 'least',\n",
       " 'level',\n",
       " 'life',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'line',\n",
       " 'little',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'make',\n",
       " 'making',\n",
       " 'man',\n",
       " 'manages',\n",
       " 'material',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'men',\n",
       " 'message',\n",
       " 'might',\n",
       " 'mind',\n",
       " 'minute',\n",
       " 'moment',\n",
       " 'mostly',\n",
       " 'moving',\n",
       " 'mr',\n",
       " 'much',\n",
       " 'music',\n",
       " 'narrative',\n",
       " 'nearly',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'nothing',\n",
       " 'offer',\n",
       " 'often',\n",
       " 'old',\n",
       " 'one',\n",
       " 'original',\n",
       " 'part',\n",
       " 'people',\n",
       " 'performance',\n",
       " 'picture',\n",
       " 'piece',\n",
       " 'place',\n",
       " 'play',\n",
       " 'pleasure',\n",
       " 'point',\n",
       " 'portrait',\n",
       " 'power',\n",
       " 'predictable',\n",
       " 'premise',\n",
       " 'pretty',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 'real',\n",
       " 'reason',\n",
       " 'right',\n",
       " 'role',\n",
       " 'romance',\n",
       " 'romantic',\n",
       " 'scene',\n",
       " 'screen',\n",
       " 'screenplay',\n",
       " 'script',\n",
       " 'seem',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'sense',\n",
       " 'series',\n",
       " 'set',\n",
       " 'short',\n",
       " 'shot',\n",
       " 'show',\n",
       " 'silly',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'smart',\n",
       " 'solid',\n",
       " 'something',\n",
       " 'sometimes',\n",
       " 'sort',\n",
       " 'special',\n",
       " 'star',\n",
       " 'start',\n",
       " 'still',\n",
       " 'story',\n",
       " 'strong',\n",
       " 'study',\n",
       " 'style',\n",
       " 'subject',\n",
       " 'surprise',\n",
       " 'surprisingly',\n",
       " 'sweet',\n",
       " 'take',\n",
       " 'tale',\n",
       " 'talent',\n",
       " 'tell',\n",
       " 'theater',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'though',\n",
       " 'three',\n",
       " 'thriller',\n",
       " 'time',\n",
       " 'title',\n",
       " 'together',\n",
       " 'tone',\n",
       " 'true',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turn',\n",
       " 'two',\n",
       " 'u',\n",
       " 'ultimately',\n",
       " 'version',\n",
       " 'video',\n",
       " 'viewer',\n",
       " 'visual',\n",
       " 'wa',\n",
       " 'war',\n",
       " 'watch',\n",
       " 'watching',\n",
       " 'way',\n",
       " 'well',\n",
       " 'whole',\n",
       " 'whose',\n",
       " 'wit',\n",
       " 'without',\n",
       " 'wo',\n",
       " 'woman',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'year',\n",
       " 'yet',\n",
       " 'young']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_idf_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling using LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visa/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.08 s, sys: 12 ms, total: 8.09 s\n",
      "Wall time: 8.09 s\n",
      "\n",
      "Topics using Latent Dirichlet Allocation model with Term frequencies: \n",
      "\n",
      "Topic #0:\n",
      "ha comedy work doe much audience way thing thriller le\n",
      "Topic #1:\n",
      "good feel never bad time director something better every like\n",
      "Topic #2:\n",
      "one performance funny u best well sense make often yet\n",
      "Topic #3:\n",
      "little life character drama take like story script big give\n",
      "Topic #4:\n",
      "wa love nothing action enough fun kind moment de first\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=5, max_iter=10,learning_method='online',learning_offset=10.,random_state=1)\n",
    "%time lda.fit(term_idf_matrix)\n",
    "print(\"\\nTopics using Latent Dirichlet Allocation model with Term frequencies: \\n\")\n",
    "print_top_words(lda, term_idf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Avoid noise in unigrams, TFIDF matrix on bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.58 s, sys: 12 ms, total: 4.59 s\n",
      "Wall time: 4.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10662, 395)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_idf_vectorizer       = TfidfVectorizer(max_df=0.99, max_features=2000,min_df=0.0005, stop_words=stops, use_idf=True, tokenizer=tokenize, ngram_range=(2,3))\n",
    "%time term_idf_matrix     = term_idf_vectorizer.fit_transform(imd.comments) \n",
    "term_idf_feature_names    = term_idf_vectorizer.get_feature_names()\n",
    "term_idf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Modelling using LDA ( with bigrams and trigams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visa/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.91 s, sys: 64 Âµs, total: 4.91 s\n",
      "Wall time: 4.91 s\n",
      "\n",
      "Topics using Latent Dirichlet Allocation model with Term frequencies: \n",
      "\n",
      "Topic #0:\n",
      "soap opera running time character study one thing sense humor young woman good intention enough make much better ha done\n",
      "Topic #1:\n",
      "love story worth seeing blue crush long time stealing harvard doe make woody allen motion picture every bit home video\n",
      "Topic #2:\n",
      "romantic comedy play like look like two hour new york make u high school whole lot try hard waste time\n",
      "Topic #3:\n",
      "big screen action sequence give u whole thing may find reign fire guilty pleasure doe much seem like human nature\n",
      "Topic #4:\n",
      "feel like special effect subject matter never quite good time de niro one best year ago high crime pretty much\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=5, max_iter=10,learning_method='online',learning_offset=10.,random_state=1)\n",
    "%time lda.fit(term_idf_matrix)\n",
    "print(\"\\nTopics using Latent Dirichlet Allocation model with Term frequencies: \\n\")\n",
    "print_top_words(lda, term_idf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic modeling using NMF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 256 ms, sys: 233 ms, total: 489 ms\n",
      "Wall time: 183 ms\n",
      "\n",
      "Fitting the Non-negative Matrix Factorization model with tf-idf features: \n",
      "\n",
      "Topic #0:\n",
      "romantic comedy sandra bullock hugh grant interesting character new york much fun start finish point view might well one greatest\n",
      "Topic #1:\n",
      "feel like still feel doe feel make feel one feel like one two hour spy kid tv series three hour\n",
      "Topic #2:\n",
      "play like like one like bad big screen young woman seem like whole thing point view never seen after-school special\n",
      "Topic #3:\n",
      "love story lan yu story one birthday girl edge seat one best like bad good intention good job good thing\n",
      "Topic #4:\n",
      "special effect action sequence jackie chan minority report hollywood ending queen damned time machine funny moment after-school special harry potter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "%time nmf = NMF(n_components=5, random_state=1,alpha=.1, l1_ratio=.5).fit(term_idf_matrix)\n",
    "print(\"\\nFitting the Non-negative Matrix Factorization model with tf-idf features: \\n\")\n",
    "print_top_words(nmf, term_idf_feature_names, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
